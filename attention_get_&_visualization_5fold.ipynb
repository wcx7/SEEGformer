{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "from torch.utils.data import DataLoader\n",
    "import ChannelBasedTransformer_fft\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score, average_precision_score, roc_auc_score, precision_recall_curve, auc\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import datetime\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from utils import fft\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import interp1d\n",
    "import patient_information\n",
    "import ChannelBasedTransformer_fft_PE\n",
    "from sklearn.model_selection import KFold\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        target = self.targets[index]\n",
    "        return sample, target\n",
    "\n",
    "\n",
    "def precision_at_k(y_true, k):\n",
    "    # 计算前k正确率\n",
    "    return np.sum(y_true[0:k])/k\n",
    "\n",
    "def recall_at_k(y_true, k):\n",
    "    # 计算召回率\n",
    "    return np.sum(y_true[0:k]) / np.sum(y_true)\n",
    "\n",
    "def f1_at_k(y_true, k):\n",
    "    prec = precision_at_k(y_true, k)\n",
    "    rec = recall_at_k(y_true, k)\n",
    "    # 计算F1分数\n",
    "    return 2 * (prec * rec) / (prec + rec) if (prec + rec) > 0 else 0\n",
    "\n",
    "def averaged_precision_at_k(y_true, k):\n",
    "    total = 0\n",
    "    for i in range(k):\n",
    "        total += precision_at_k(y_true, i+1)\n",
    "    return total/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_name_list = [ ]\n",
    "data_agu_list = [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(patient_name_list)):\n",
    "    patient_name = patient_name_list[i]\n",
    "    print(patient_name)\n",
    "    # 获得通道名称ch_names\n",
    "    patient = getattr(patient_information, patient_name)()\n",
    "    position_encoding = np.load(f'../position_encoding_{patient_name}.npy')\n",
    "    filename = next(iter(patient.seizure_start_dict.keys()))\n",
    "    useless_chan = patient_information.useless_chan\n",
    "    exclude = patient.exclude\n",
    "    exclude = useless_chan + exclude\n",
    "    if patient_name == 'ZhangQian' or patient_name == 'XuJunwei':\n",
    "        raw = read_raw_edf(f'../{patient_name}/S1.edf',preload=False,encoding='latin1',exclude=exclude)\n",
    "    else:\n",
    "        raw = read_raw_edf(f'../{patient_name}/{filename}.edf',preload=False,encoding='latin1',exclude=exclude)\n",
    "    ch_names = raw.ch_names\n",
    "    print(ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载可解释数据集\n",
    "patient = getattr(patient_information, patient_name)()\n",
    "filename = next(iter(patient.seizure_start_dict.keys()))\n",
    "useless_chan = patient_information.useless_chan\n",
    "exclude = patient.exclude\n",
    "exclude = useless_chan + exclude\n",
    "\n",
    "ch_names = patient.ch_names\n",
    "for p in range(len(ch_names)):\n",
    "    # 移除 'EEG '\n",
    "    ch_names[p] = ch_names[p].replace('EEG ', '')\n",
    "\n",
    "    # 如果字符串不以 \"POL \" 开头，则添加 \"POL \"\n",
    "    if not ch_names[p].startswith('POL '):\n",
    "        ch_names[p] = 'POL ' + ch_names[p]\n",
    "    # 使用正则表达式移除 '-' 之后的所有字符\n",
    "    ch_names[p] = re.sub('-.*', '', ch_names[p])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据准备 发作   ***评价时推荐使用数据增强之前的原始数据，即窗宽1s，步长1s***\n",
    "dataset_path = f'../{patient_name}/preprocessed_data_1s_1s(Z-Score)/'\n",
    "data = np.load(os.path.join(dataset_path,'seizure/all_data.npy'))\n",
    "data = np.transpose(data,(2, 0, 1))\n",
    "labels = np.load(os.path.join(dataset_path,'seizure/label.npy'))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "n_chans = data.shape[1]\n",
    "num_heads = 4\n",
    "embed_dim = 64   # 64\n",
    "mlp_ratio = 2\n",
    "dropout = 0\n",
    "num_blocks = 2\n",
    "num_classes = 2\n",
    "fs = 1000\n",
    "fft_points = data.shape[2]*2\n",
    "freq_used = 100  # 只使用 freq_used Hz以下的信息\n",
    "fft_dim = int(freq_used*fft_points/fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定位效果定量评价    注意是不是要放大高频！注意随机种子！\n",
    "if patient.PE == 1:\n",
    "    position_encoding = np.load(f'../position_encoding_{patient_name}.npy')\n",
    "\n",
    "scoring_method = 'mid'\n",
    "\n",
    "# 定位效果定量评价\n",
    "# 主文件夹路径\n",
    "main_folder_path = f'../{patient_name}'\n",
    "# 子文件夹名称\n",
    "folds = ['fold1', 'fold2', 'fold3', 'fold4', 'fold5']\n",
    "dataset_dict = {'dataset1':CustomDataset(data, labels),'dataset2':CustomDataset(data, labels),\n",
    "                'dataset3':CustomDataset(data, labels),'dataset4':CustomDataset(data, labels),'dataset5':CustomDataset(data, labels)}\n",
    "frequency = np.zeros([5, len(ch_names)])\n",
    "average_score = np.zeros([5, len(ch_names)])\n",
    "i=0\n",
    "\n",
    "# 使用 for 循环依次访问这五个子文件夹\n",
    "for fold in folds:\n",
    "    i += 1\n",
    "    # 构造当前 fold 的完整路径\n",
    "    current_fold_path = os.path.join(main_folder_path, fold)\n",
    "    if patient.PE == 1:\n",
    "        model = ChannelBasedTransformer_fft_PE.ChannelBasedTransformer_fft(num_heads, fft_dim, embed_dim, mlp_ratio, dropout, n_chans, num_blocks, num_classes, position_encoding, pool = 'cls')\n",
    "    else:\n",
    "        model = ChannelBasedTransformer_fft.ChannelBasedTransformer_fft(num_heads, fft_dim, embed_dim, mlp_ratio, dropout, n_chans, num_blocks, num_classes, pool = 'cls')\n",
    "    model.load_state_dict(torch.load(current_fold_path + '/train_fft.pth'))\n",
    "    model.eval()        # 将模型切换到评估模式\n",
    "    model.to(device)\n",
    "    dataset = dataset_dict[f'dataset{i}']\n",
    "    data_loader = DataLoader(dataset = dataset, batch_size=batch_size, shuffle=False, drop_last = False)\n",
    "    # 初始化空列表以保存预测和真实标签\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_attention_scores_real_testset = []\n",
    "    all_attention_scores_imag_testset = []\n",
    "    all_attention_scores_abs_testset = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs, labels = batch\n",
    "            _, x_real, x_imag, x_abs = fft(inputs, fs, fft_points, freq_used)\n",
    "            x_real = torch.Tensor(x_real).to(device)\n",
    "            x_imag = torch.Tensor(x_imag).to(device)\n",
    "            x_abs = torch.Tensor(x_abs).to(device)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # 将数据移动到GPU上\n",
    "            outputs,attn_weights_real, attn_weights_imag, attn_weights_abs = model(x_real, x_imag, x_abs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predicted.tolist())\n",
    "            all_targets.extend(labels.tolist())\n",
    "            all_attention_scores_real_testset.append(attn_weights_real)\n",
    "            all_attention_scores_imag_testset.append(attn_weights_imag)\n",
    "            all_attention_scores_abs_testset.append(attn_weights_abs)\n",
    "\n",
    "    # 测试集上的模型表现\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    precision = precision_score(all_targets, all_predictions, average='binary')\n",
    "    recall = recall_score(all_targets, all_predictions, average='binary')\n",
    "    f1 = f1_score(all_targets, all_predictions, average='binary')\n",
    "    \n",
    "    combined_tensor = torch.cat(all_attention_scores_real_testset, dim=0) + torch.cat(all_attention_scores_imag_testset, dim=0)\n",
    "    combined_tensor = combined_tensor.cpu().numpy()\n",
    "    combined_tensor_mean = np.mean(combined_tensor, axis=1)\n",
    "    attention_score = combined_tensor_mean\n",
    "    min_val = np.min(attention_score)\n",
    "    max_val = np.max(attention_score)\n",
    "    attention_score = attention_score.T\n",
    "    # Min-Max标准化\n",
    "    attention_score = attention_score[1:,:]   # 去除cls\n",
    "    scaled_attention_score = (attention_score - min_val) / (max_val - min_val)\n",
    "    if scoring_method == 'mid':\n",
    "        #中位数法\n",
    "        q1 = np.percentile(scaled_attention_score, 50)\n",
    "        frequency_temp = np.sum(scaled_attention_score > q1, axis=1)\n",
    "        frequency_temp = (frequency_temp - np.min(frequency_temp)) / (np.max(frequency_temp) - np.min(frequency_temp))\n",
    "        frequency[i-1,:] = frequency_temp\n",
    "        result_dict_mid = {}\n",
    "        for k in range(len(ch_names)):\n",
    "            result_dict_mid[ch_names[k]] = frequency_temp[k]\n",
    "    else:\n",
    "        #平均法\n",
    "        channel_total = np.mean(scaled_attention_score, axis = 1)\n",
    "        channel_total = (channel_total - np.min(channel_total)) / (np.max(channel_total) - np.min(channel_total))\n",
    "        average_score[i-1,:] = channel_total\n",
    "        result_dict_ave = {}\n",
    "        for k in range(len(ch_names)):\n",
    "            result_dict_ave[ch_names[k]] = channel_total[k]\n",
    "            \n",
    "if scoring_method == 'mid':\n",
    "    #中位数法\n",
    "    stds = np.std(frequency, axis=0)\n",
    "    frequency = np.mean(frequency, axis=0)\n",
    "    result_dict_mid = {}\n",
    "    for k in range(len(ch_names)):\n",
    "        result_dict_mid[ch_names[k]] = frequency[k]\n",
    "sorted_dict = dict(sorted(result_dict_mid.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算PLV\n",
    "PLV_dict = {}\n",
    "\n",
    "# 遍历 ch_names 列表中的每个字符串和 scaled_attention_score 中的每一行\n",
    "for name, scores in zip(ch_names, scaled_attention_score):\n",
    "    # 将每个字符串作为字典的键，相应的 scores 作为值\n",
    "    PLV_dict[name] = scores.tolist()  # 将 numpy 数组转换为 Python 列表\n",
    "\n",
    "#中位数法\n",
    "q1 = np.percentile(scaled_attention_score, 50)\n",
    "# 创建一个空字典用于存储结果\n",
    "positions = {}\n",
    "\n",
    "# 遍历 patient.EZ 中的每个通道\n",
    "for name in patient.EZ:\n",
    "    # 检查该字符串是否在 result_dict 中\n",
    "    if name in PLV_dict:\n",
    "        # 获取该字符串对应的值列表\n",
    "        values = PLV_dict[name]\n",
    "        # 初始化一个空列表，用于存储大于 q1 的值在列表中的位置\n",
    "        greater_than_q1_positions = []\n",
    "        # 遍历该值列表\n",
    "        for i, value in enumerate(values):\n",
    "            # 如果值大于 q1，则将其位置添加到列表中\n",
    "            if value > q1:\n",
    "                greater_than_q1_positions.append(i)\n",
    "        # 将该字符串的大于 q1 的值的位置列表存储到结果字典中\n",
    "        positions[name] = greater_than_q1_positions\n",
    "\n",
    "# 创建一个空集合用于存储所有位置列表的并集\n",
    "key_second = set()\n",
    "\n",
    "# 遍历 positions 字典中的每个键值对\n",
    "for positions_list in positions.values():\n",
    "    # 将当前键对应的位置列表添加到并集中\n",
    "    key_second.update(positions_list)\n",
    "key_second = list(key_second)\n",
    "\n",
    "key_channel_position = []\n",
    "# 遍历 patient.EZ 中的每个通道\n",
    "for name in patient.EZ:\n",
    "    key_channel_position.append(ch_names.index(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算PLV数据准备\n",
    "dataset_path = f'../preprocessed_data_1s_1s(Z-Score)/'\n",
    "seizure_data = np.load(os.path.join(dataset_path,'seizure/all_data.npy'))\n",
    "seizure_data = np.transpose(seizure_data,(2, 0, 1))\n",
    "preseizure_data = np.load(os.path.join(dataset_path,'preseizure/all_data.npy'))\n",
    "preseizure_data = np.transpose(preseizure_data,(2, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算PLV\n",
    "from scipy.signal import hilbert\n",
    "\n",
    "# 相位锁定值（Phase Locking Value, PLV）单个值 无向\n",
    "def phase_locking_value(x, y):\n",
    "    # 计算信号的解析信号\n",
    "    analytic_signal_x = hilbert(x)\n",
    "    analytic_signal_y = hilbert(y)\n",
    "    # 获取相位\n",
    "    phases_x = np.angle(analytic_signal_x)\n",
    "    phases_y = np.angle(analytic_signal_y)\n",
    "    complex_phase_diff = np.exp(complex(0,1)*(phases_x - phases_y))\n",
    "    plv = np.abs(np.sum(complex_phase_diff))/len(phases_x)\n",
    "    return plv\n",
    "\n",
    "seizure_data.astype(np.float16)\n",
    "preseizure_data.astype(np.float16)\n",
    "sei_PLV = np.zeros([seizure_data.shape[0],len(ch_names),len(ch_names)])\n",
    "pre_PLV = np.zeros([preseizure_data.shape[0],len(ch_names),len(ch_names)])\n",
    "for i in range(seizure_data.shape[1]):\n",
    "    for j in range(len(ch_names)):\n",
    "        for k in range(j, len(ch_names)):\n",
    "            plv = phase_locking_value(seizure_data[:,i,j], seizure_data[:,i,k])\n",
    "            sei_PLV[i,j,k] = plv\n",
    "            sei_PLV[i,k,j] = plv\n",
    "\n",
    "for i in range(preseizure_data.shape[1]):\n",
    "    for j in range(len(ch_names)):\n",
    "        for k in range(j, len(ch_names)):\n",
    "            plv = phase_locking_value(preseizure_data[:,i,j], preseizure_data[:,i,k])\n",
    "            pre_PLV[i,j,k] = plv\n",
    "            pre_PLV[i,k,j] = plv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noez_channel = [x for x in list(range(sei_PLV.shape[1])) if x not in key_channel_position]\n",
    "ez_plv_seizure = sei_PLV[key_second][:,key_channel_position][:,:,key_channel_position]\n",
    "noez_plv_seizure = sei_PLV[key_second][:,noez_channel][:,:,noez_channel]\n",
    "intra_seizure = sei_PLV[key_second][:,key_channel_position][:,:,noez_channel]\n",
    "ez_plv_pre = pre_PLV[:,key_channel_position][:,:,key_channel_position]\n",
    "noez_plv_pre = pre_PLV[:,noez_channel][:,:,noez_channel]\n",
    "intra_pre = pre_PLV[:,key_channel_position][:,:,noez_channel]\n",
    "print('ez_plv_seizure:',np.mean(ez_plv_seizure))\n",
    "print('noez_plv_seizure:',np.mean(noez_plv_seizure))\n",
    "print('intra_seizure:',np.mean(intra_seizure))\n",
    "print('ez_plv_pre:',np.mean(ez_plv_pre))\n",
    "print('noez_plv_pre:',np.mean(noez_plv_pre))\n",
    "print('intra_pre:',np.mean(intra_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 热力值显示\n",
    "def heatmap_visualization(scaled_attention_score, data, start_time, end_time, start_channel, end_channel, ch_names, fs = 1000, downsample_scale = 5):\n",
    "    # original_data 是矩阵\n",
    "    original_data = scaled_attention_score[:,start_time:end_time]\n",
    "\n",
    "    # 创建新的 x 轴坐标（列插值）\n",
    "    x_old = np.linspace(0, 1, original_data.shape[1])\n",
    "    x_new = np.linspace(0, 1, original_data.shape[1]*1000)\n",
    "    # 对每一行进行列插值\n",
    "    expanded_data_cols = np.array([interp1d(x_old, row, kind='linear')(x_new) for row in original_data])\n",
    "\n",
    "    # 创建新的 y 轴坐标（行插值）\n",
    "    y_old = np.linspace(0, 1, original_data.shape[0])\n",
    "    y_new = np.linspace(0, 1, original_data.shape[0]*10)\n",
    "    # 对整个数据集进行行插值\n",
    "    expanded_data1 = np.array([interp1d(y_old, expanded_data_cols[:, i], kind='linear')(y_new) for i in range(expanded_data_cols.shape[1])]).T\n",
    "    # 取出前五行 下面是对前五行做一个对称填充以便通道和热力图可以对齐\n",
    "    top_five_rows = expanded_data1[:5, :]\n",
    "    # 将这五行上下颠倒（沿着第一个轴）\n",
    "    flipped_top_five_rows = np.flipud(top_five_rows)\n",
    "    # 将颠倒后的五行拼接到原矩阵的顶部\n",
    "    expanded_data1 = np.vstack((flipped_top_five_rows, expanded_data1))\n",
    "\n",
    "    # 可视化\n",
    "    data = data[start_time:end_time,:,:]\n",
    "    # 首先，转置数组，使其形状变为 (181, start_time:end_time, 1000)\n",
    "    data_transposed = np.transpose(data, (1, 0, 2))\n",
    "    # 然后，使用reshape方法将其转换为 (181, 1000*(end_time-start_time))\n",
    "    reshaped_data1 = data_transposed.reshape(data_transposed.shape[0], -1)\n",
    "\n",
    "    plt.figure(figsize=(20*(end_time-start_time)/20, 8*(end_channel-start_channel)/30))  # 设置图的大小\n",
    "    # 降采样\n",
    "    downsample_scale = 5\n",
    "    reshaped_data = reshaped_data1[start_channel:end_channel+1, ::downsample_scale]\n",
    "    fs = fs/downsample_scale\n",
    "    # 取相应的热力图\n",
    "    expanded_data = expanded_data1[start_channel*10:end_channel*10+10,::downsample_scale]\n",
    "    # 绘制热力图\n",
    "    ax = sns.heatmap(expanded_data, cmap=\"OrRd\",shading='gouraud', vmin=0, vmax=1, cbar_kws={'label': 'Attention Score', 'orientation': 'horizontal', \"pad\":0.02,'shrink':0.5})   # , vmin=0, vmax=1\n",
    "    # cbar_kws={'label': 'ColorbarName', #color bar的名称\n",
    "    #                        'orientation': 'horizontal',#color bar的方向设置，默认为'vertical'，可水平显示'horizontal'\n",
    "    #                        \"ticks\":np.arange(4.5,8,0.5),#color bar中刻度值范围和间隔\n",
    "    #                        \"format\":\"%.3f\",#格式化输出color bar中刻度值\n",
    "    #                        \"pad\":0.15,#color bar与热图之间距离，距离变大热图会被压缩}\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    # 设置colorbar的刻度值和对应的标签\n",
    "    cbar.set_ticks([0,1])\n",
    "    cbar.set_ticklabels(['Low', 'High'])                                               \n",
    "\n",
    "    # 绘制每一行数据，使它们在y轴上垂直偏移\n",
    "    for i in range(reshaped_data.shape[0]):\n",
    "        plt.plot(reshaped_data[i, :]*1.25 + 5 + i*10, color='black', linewidth=0.5)  # 偏移量可以根据需要调整    \n",
    "    # 设置图表的边界\n",
    "    plt.margins(x=0, y=0)\n",
    "    # 设置X轴标签\n",
    "    plt.xlabel(\"time(s)\")\n",
    "    plt.title(\"Time-Attention Heatmap\")\n",
    "    # 设置Y轴刻度和标签\n",
    "    y_labels = ch_names[start_channel:end_channel+1]\n",
    "    y_ticks = [5+i*10 for i in range(reshaped_data.shape[0])]   # np.linspace(0,expanded_data.shape[0]-10, reshaped_data.shape[0])+5  \n",
    "    plt.yticks(y_ticks, labels=y_labels)\n",
    "    x_ticks = np.linspace(0, int(reshaped_data.shape[1]), int(reshaped_data.shape[1]/fs)+1)\n",
    "    x_labels = [str(i) for i in range(0, int(reshaped_data.shape[1]/fs)+1)]  \n",
    "    plt.xticks(x_ticks, labels=x_labels, rotation=0)\n",
    "    # 设置刻度的凸起朝外\n",
    "    plt.tick_params(direction='out')\n",
    "    # 显示图表\n",
    "    plt.show()\n",
    "start_time = 0\n",
    "end_time = 20\n",
    "start_channel=0\n",
    "end_channel=167\n",
    "ch_names = ch_names\n",
    "heatmap_visualization(scaled_attention_score, data, start_time, end_time, start_channel, end_channel, ch_names, fs = 1000, downsample_scale = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量绘制热力图并保存\n",
    "formatted_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "for i in range(data.shape[0]//20):\n",
    "    start_time = i*20\n",
    "    end_time = (i+1)*20\n",
    "    start_channel=0\n",
    "    end_channel=167        # 这里要改，通道总数\n",
    "    ch_names = ch_names\n",
    "    # original_data 是矩阵\n",
    "    original_data = scaled_attention_score[:,start_time:end_time]\n",
    "\n",
    "    # 创建新的 x 轴坐标（列插值）\n",
    "    x_old = np.linspace(0, 1, original_data.shape[1])\n",
    "    x_new = np.linspace(0, 1, original_data.shape[1]*1000)\n",
    "    # 对每一行进行列插值\n",
    "    expanded_data_cols = np.array([interp1d(x_old, row, kind='linear')(x_new) for row in original_data])\n",
    "\n",
    "    # 创建新的 y 轴坐标（行插值）\n",
    "    y_old = np.linspace(0, 1, original_data.shape[0])\n",
    "    y_new = np.linspace(0, 1, original_data.shape[0]*10)\n",
    "    # 对整个数据集进行行插值\n",
    "    expanded_data1 = np.array([interp1d(y_old, expanded_data_cols[:, i], kind='linear')(y_new) for i in range(expanded_data_cols.shape[1])]).T\n",
    "    # 取出前五行 下面是对前五行做一个对称填充以便通道和热力图可以对齐\n",
    "    top_five_rows = expanded_data1[:5, :]\n",
    "    # 将这五行上下颠倒（沿着第一个轴）\n",
    "    flipped_top_five_rows = np.flipud(top_five_rows)\n",
    "    # 将颠倒后的五行拼接到原矩阵的顶部\n",
    "    expanded_data1 = np.vstack((flipped_top_five_rows, expanded_data1))\n",
    "\n",
    "    # 可视化\n",
    "    data_temp = data[start_time:end_time,:,:]\n",
    "    # 首先，转置数组，使其形状变为 (181, start_time:end_time, 1000)\n",
    "    data_transposed = np.transpose(data_temp, (1, 0, 2))\n",
    "    # 然后，使用reshape方法将其转换为 (181, 1000*(end_time-start_time))\n",
    "    reshaped_data1 = data_transposed.reshape(data_transposed.shape[0], -1)\n",
    "    plt.figure(figsize=(20*(end_time-start_time)/20, 8*(end_channel-start_channel)/30))  # 设置图的大小\n",
    "    # 降采样\n",
    "    downsample_scale = 5\n",
    "    reshaped_data = reshaped_data1[start_channel:end_channel+1, ::downsample_scale]\n",
    "    fs1 = fs/downsample_scale\n",
    "    # 取相应的热力图\n",
    "    expanded_data = expanded_data1[start_channel*10:end_channel*10+10,::downsample_scale]\n",
    "    # 绘制热力图\n",
    "    ax = sns.heatmap(expanded_data, cmap=\"OrRd\",shading='gouraud', vmin=0, vmax=1, cbar_kws={'label': 'Attention Score', 'orientation': 'horizontal', \"pad\":0.02,'shrink':0.5})   # , vmin=0, vmax=1\n",
    "    # cbar_kws={'label': 'ColorbarName', #color bar的名称\n",
    "    #                        'orientation': 'horizontal',#color bar的方向设置，默认为'vertical'，可水平显示'horizontal'\n",
    "    #                        \"ticks\":np.arange(4.5,8,0.5),#color bar中刻度值范围和间隔\n",
    "    #                        \"format\":\"%.3f\",#格式化输出color bar中刻度值\n",
    "    #                        \"pad\":0.15,#color bar与热图之间距离，距离变大热图会被压缩}\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    # 设置colorbar的刻度值和对应的标签\n",
    "    cbar.set_ticks([0,1])\n",
    "    cbar.set_ticklabels(['Low', 'High'])                                               \n",
    "    # 绘制每一行数据，使它们在y轴上垂直偏移\n",
    "    for k in range(reshaped_data.shape[0]):\n",
    "        plt.plot(reshaped_data[k, :]*1.25 + 5 + k*10, color='black', linewidth=0.5)  # 偏移量可以根据需要调整    \n",
    "    # 设置图表的边界\n",
    "    plt.margins(x=0, y=0)\n",
    "    # 设置X轴标签\n",
    "    plt.xlabel(\"time(s)\")\n",
    "    plt.title(\"Time-Attention Heatmap\")\n",
    "    # 设置Y轴刻度和标签\n",
    "    y_labels = ch_names[start_channel:end_channel+1]\n",
    "    y_ticks = [5+k*10 for k in range(reshaped_data.shape[0])]   # np.linspace(0,expanded_data.shape[0]-10, reshaped_data.shape[0])+5  \n",
    "    plt.yticks(y_ticks, labels=y_labels)\n",
    "    x_ticks = np.linspace(0, int(reshaped_data.shape[1]), int(reshaped_data.shape[1]/fs1)+1)\n",
    "    x_labels = [str(k) for k in range(start_time, start_time+int(reshaped_data.shape[1]/fs1)+1)]  \n",
    "    plt.xticks(x_ticks, labels=x_labels, rotation=0)\n",
    "    # 设置刻度的凸起朝外\n",
    "    plt.tick_params(direction='out')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f'../Time_attention_map/{patient_name}/{start_time}~{end_time}s {formatted_time}.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wangcx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
